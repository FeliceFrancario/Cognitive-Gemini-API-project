This project explores the analogical reasoning capabilities of large language models (LLMs) through
the lens of the Relational Luring Effect, a cognitive phenomenon where individuals are more likely
to falsely remember or recognize non-presented items related to presented information. Building on
the theoretical framework established by Popov et al., we conducted two experiments to assess the
Gemini 1.5 flash LLMâ€™s performance in associative recognition tasks involving relational lures. In
Experiment 1, the LLM demonstrated a tendency towards the Relational Luring Effect similar to
that observed in human participants, with a higher tendency to falsely recognize relationally similar
pairs as previously seen, although this was not statistically significant. In Experiment 2, the LLM
did not exhibit the Relational Luring Effect, likely due to its perfect memory for intact word pairs.
These findings suggest that while LLMs can simulate certain aspects of human analogical reasoning,
their perfect memory for studied items may lead to differences in behavior compared to human
cognition.
